{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6xxW8bEr/eoE7pi0NRva5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaixih/JAX101/blob/master/pjit_flax_named.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CWCgcY0Tvz-_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
        "import jax\n",
        "\n",
        "from jax import lax, random, numpy as jnp\n",
        "\n",
        "import flax\n",
        "from flax import struct, traverse_util, linen as nn\n",
        "from flax.linen import spmd # Flax Linen SPMD."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.experimental.pjit import pjit, with_sharding_constraint\n",
        "from jax.sharding import Mesh, PartitionSpec\n",
        "from jax.experimental import mesh_utils\n",
        "\n",
        "# Start a device mesh.\n",
        "device_mesh = mesh_utils.create_device_mesh((4, 2))\n",
        "\n",
        "# Annotate each axis with a name.\n",
        "mesh = Mesh(devices=device_mesh, axis_names=('data', 'model'))\n",
        "mesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVTnWM0bwCc6",
        "outputId": "697ff06d-14c0-479b-b195-5bc0226aea8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mesh(device_ids=array([[0, 1],\n",
              "       [2, 3],\n",
              "       [4, 5],\n",
              "       [6, 7]]), axis_names=('data', 'model'))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperDot(nn.Module):\n",
        "  depth: int\n",
        "  max_history_length: int\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    W1 = self.param(\n",
        "        'W1', \n",
        "        nn.with_partitioning(nn.initializers.xavier_normal(), (None, 'model')),\n",
        "        (x.shape[-1], self.depth))\n",
        "    x_max_history = self.variable(\n",
        "        'fp8_params', 'x_max_history',\n",
        "        nn.with_partitioning(nn.initializers.zeros_init(), (None,)),\n",
        "        self.make_rng('fp8_params'), (self.max_history_length,))\n",
        "    x_scale = self.variable(\n",
        "        'fp8_params', 'x_scale', \n",
        "        nn.with_partitioning(nn.initializers.ones_init(), (None,)),\n",
        "        self.make_rng('fp8_params'), (1,))\n",
        "    \n",
        "    # Do something to use the old x_scale.\n",
        "    y = jnp.dot(x * x_scale.value, W1)\n",
        "    x_max = jnp.max(x, axis=(0, 1), keepdims=True)\n",
        "\n",
        "    # Do something to update the max_history and the new scale.\n",
        "    x_max_history.value = x_max_history.value.at[0].set(x_max[0 ,0])\n",
        "    x_max_history.value = jnp.roll(x_max_history.value, -1, axis=0)\n",
        "    x_scale.value = x_scale.value / jnp.max(x_max_history.value)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "Ppd4zK6XwFl_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = jax.random.normal(jax.random.PRNGKey(0), (8192, 8192))\n",
        "k = random.PRNGKey(0)\n",
        "\n",
        "model = SuperDot(8192, 16)"
      ],
      "metadata": {
        "id": "ELOgYCfnwT2c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A functional way of model initialization.\n",
        "def init_fn(k, x):\n",
        "  rngs = {'params': k, 'fp8_params': k}\n",
        "  variables = model.init(rngs, x) # Initialize the model.\n",
        "  return variables\n",
        "\n",
        "abstract_variables = jax.eval_shape(init_fn, k, x)\n",
        "# This `state_spec` has the same pytree structure as the output\n",
        "# of the `init_fn`.\n",
        "state_spec = nn.get_partition_spec(abstract_variables)\n",
        "state_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt3-HlQ8xnFz",
        "outputId": "78392279-68a4-4d1d-ace6-4124e462b0d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    fp8_params: {\n",
              "        x_max_history: PartitionSpec(None,),\n",
              "        x_scale: PartitionSpec(None,),\n",
              "    },\n",
              "    params: {\n",
              "        W1: PartitionSpec(None, 'model'),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pjit_init_fn = pjit(init_fn,\n",
        "                    in_axis_resources=(PartitionSpec(None), PartitionSpec('data', None)),  # PRNG key and x\n",
        "                    out_axis_resources=state_spec,  # params\n",
        "                    )\n",
        "# if in_axis_resources, we need mesh context\n",
        "with mesh:\n",
        "  initialized_state = pjit_init_fn(k, x)\n",
        "jax.tree_map(jnp.shape, initialized_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft9W197Cx50B",
        "outputId": "6807f216-be26-4cca-a52e-a6cd669af84c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    fp8_params: {\n",
              "        x_max_history: Partitioned(value=(16,), names=(None,), mesh=None),\n",
              "        x_scale: Partitioned(value=(1,), names=(None,), mesh=None),\n",
              "    },\n",
              "    params: {\n",
              "        W1: Partitioned(value=(8192, 8192), names=(None, 'model'), mesh=None),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(initialized_state['params']['W1'].value.sharding)\n",
        "print(initialized_state['fp8_params']['x_max_history'].value.sharding)\n",
        "print(initialized_state['fp8_params']['x_scale'].value.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYEDX0BU18IV",
        "outputId": "bd303f94-8615-465b-d3f9-17a97c583cbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GSPMDSharding({devices=[1,2,4]0,2,4,6,1,3,5,7 last_tile_dim_replicate})\n",
            "GSPMDSharding({replicated})\n",
            "GSPMDSharding({replicated})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_step(state, x):\n",
        "  rngs = {'fp8_params': jax.random.PRNGKey(0)}\n",
        "  y, new_state = model.apply({'params': state['params'], 'fp8_params': state['fp8_params']}, x, rngs=rngs, mutable=['fp8_params'])\n",
        "  return y, new_state['fp8_params']\n",
        "\n",
        "pjit_step_fn = pjit(infer_step,\n",
        "                    in_axis_resources=(state_spec, PartitionSpec('data', None)),  # params and x\n",
        "                    out_axis_resources=(PartitionSpec('data', 'model'), PartitionSpec(None))  # y and fp8_params\n",
        "                    )\n",
        "with mesh:\n",
        "  y, new_state = pjit_step_fn(initialized_state, x)\n",
        "print('y sharding:')\n",
        "jax.debug.visualize_array_sharding(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "NyAV23hx_h88",
        "outputId": "49bf3b37-c590-46df-eafc-e5a9f5d0e291"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y sharding:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m    \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m   \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107mCPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m    \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;140;162;82m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;140;162;82m   \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82mCPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m    \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m   \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m    \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;140;162;82m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;231;203;148m            \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m            \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;231;203;148m   \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148mCPU 4\u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m    \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m   \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207mCPU 5\u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m    \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;231;203;148m            \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;165;81;148m            \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m            \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;165;81;148m   \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148mCPU 6\u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m    \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m   \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49mCPU 7\u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m    \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;165;81;148m            \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m            \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">            </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">   CPU 0    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">   CPU 1    </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">            </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">   CPU 2    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">   CPU 3    </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">            </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">   CPU 4    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">   CPU 5    </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">            </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">            </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">   CPU 6    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">   CPU 7    </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">            </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mesh:\n",
        "  lowered = pjit_step_fn.lower(initialized_state, x)\n",
        "compiled = lowered.compile().compiler_ir()"
      ],
      "metadata": {
        "id": "LG9VHJBLA5nb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for module in compiled:\n",
        "  print(module.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXnyTpg5BF21",
        "outputId": "b8227533-7406-40aa-c2a5-310c77c81e2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HloModule pjit_infer_step, entry_computation_layout={(f32[16]{0},f32[1]{0},f32[8192,4096]{1,0},f32[2048,8192]{1,0})->(f32[2048,4096]{1,0}, f32[16]{0}, f32[1]{0})}, allow_spmd_sharding_propagation_to_output={false,false,false}\n",
            "\n",
            "%region_0.16 (Arg_0.17: f32[], Arg_1.18: f32[]) -> f32[] {\n",
            "  %Arg_0.17 = f32[] parameter(0)\n",
            "  %Arg_1.18 = f32[] parameter(1)\n",
            "  ROOT %maximum.19 = f32[] maximum(f32[] %Arg_0.17, f32[] %Arg_1.18), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0, 1)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=21}\n",
            "}\n",
            "\n",
            "%region_2.63 (Arg_0.64: f32[], Arg_1.65: f32[]) -> f32[] {\n",
            "  %Arg_0.64 = f32[] parameter(0)\n",
            "  %Arg_1.65 = f32[] parameter(1)\n",
            "  ROOT %maximum.66 = f32[] maximum(f32[] %Arg_0.64, f32[] %Arg_1.65), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0,)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=26}\n",
            "}\n",
            "\n",
            "%fused_computation (param_0: f32[1], param_1.4: f32[32]) -> f32[1] {\n",
            "  %param_0 = f32[1]{0} parameter(0)\n",
            "  %param_1.4 = f32[32]{0} parameter(1)\n",
            "  %slice.7 = f32[16]{0} slice(f32[32]{0} %param_1.4), slice={[1:17]}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/dynamic_slice[slice_sizes=(16,)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "  %constant.63 = f32[] constant(-inf)\n",
            "  %reduce.5 = f32[] reduce(f32[16]{0} %slice.7, f32[] %constant.63), dimensions={0}, to_apply=%region_2.63, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0,)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=26}\n",
            "  %reshape.38 = f32[1]{0} reshape(f32[] %reduce.5), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/div\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=26}\n",
            "  ROOT %divide.1 = f32[1]{0} divide(f32[1]{0} %param_0, f32[1]{0} %reshape.38), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/div\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=26}\n",
            "}\n",
            "\n",
            "%fused_computation.1 (param_0.2: f32[16]) -> f32[16] {\n",
            "  %param_0.2 = f32[16]{0} parameter(0)\n",
            "  %concatenate.3 = f32[32]{0} concatenate(f32[16]{0} %param_0.2, f32[16]{0} %param_0.2), dimensions={0}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/concatenate[dimension=0]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "  ROOT %slice.8 = f32[16]{0} slice(f32[32]{0} %concatenate.3), slice={[1:17]}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/dynamic_slice[slice_sizes=(16,)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "}\n",
            "\n",
            "%fused_computation.2 (param_0.4: f32[16], param_1.6: f32[]) -> f32[32] {\n",
            "  %param_0.4 = f32[16]{0} parameter(0)\n",
            "  %param_1.6 = f32[] parameter(1)\n",
            "  %reshape.39 = f32[1]{0} reshape(f32[] %param_1.6), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0, 1)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=21}\n",
            "  %constant.64 = s32[] constant(0)\n",
            "  %dynamic-update-slice.2 = f32[16]{0} dynamic-update-slice(f32[16]{0} %param_0.4, f32[1]{0} %reshape.39, s32[] %constant.64), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/scatter[update_consts=() dimension_numbers=ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,)) indices_are_sorted=True unique_indices=True mode=GatherScatterMode.FILL_OR_DROP]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=24}\n",
            "  ROOT %concatenate.4 = f32[32]{0} concatenate(f32[16]{0} %dynamic-update-slice.2, f32[16]{0} %dynamic-update-slice.2), dimensions={0}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/concatenate[dimension=0]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "}\n",
            "\n",
            "%fused_computation.3 (param_0.5: f32[16], param_1.9: f32[]) -> f32[16] {\n",
            "  %param_0.5 = f32[16]{0} parameter(0)\n",
            "  %param_1.9 = f32[] parameter(1)\n",
            "  %reshape.40 = f32[1]{0} reshape(f32[] %param_1.9), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0, 1)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=21}\n",
            "  %constant.65 = s32[] constant(0)\n",
            "  ROOT %dynamic-update-slice.3 = f32[16]{0} dynamic-update-slice(f32[16]{0} %param_0.5, f32[1]{0} %reshape.40, s32[] %constant.65), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/scatter[update_consts=() dimension_numbers=ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,)) indices_are_sorted=True unique_indices=True mode=GatherScatterMode.FILL_OR_DROP]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=24}\n",
            "}\n",
            "\n",
            "%fused_computation.4.clone (param_0.7: f32[2048,8192], param_1.13: f32[1]) -> f32[2048,8192] {\n",
            "  %param_0.7 = f32[2048,8192]{1,0} parameter(0)\n",
            "  %param_1.13 = f32[1]{0} parameter(1)\n",
            "  %reshape.42 = f32[] reshape(f32[1]{0} %param_1.13), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/mul\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=20}\n",
            "  %broadcast.12 = f32[2048,8192]{1,0} broadcast(f32[] %reshape.42), dimensions={}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/mul\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=20}\n",
            "  ROOT %multiply.2 = f32[2048,8192]{1,0} multiply(f32[2048,8192]{1,0} %param_0.7, f32[2048,8192]{1,0} %broadcast.12), metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/mul\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=20}\n",
            "}\n",
            "\n",
            "%parallel_fusion.4 (p: f32[2048,8192], p.1: f32[1]) -> f32[2048,8192] {\n",
            "  %p = f32[2048,8192]{1,0} parameter(0)\n",
            "  %p.1 = f32[1]{0} parameter(1)\n",
            "  ROOT %fusion.4.clone = f32[2048,8192]{1,0} fusion(f32[2048,8192]{1,0} %p, f32[1]{0} %p.1), kind=kLoop, calls=%fused_computation.4.clone, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/mul\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=20}, backend_config=\"{\\\"outer_dimension_partitions\\\":[\\\"2\\\"]}\"\n",
            "}\n",
            "\n",
            "ENTRY %main.74_spmd (param.3: f32[16], param.1: f32[1], param.2: f32[8192,4096], param: f32[2048,8192]) -> (f32[2048,4096], f32[16], f32[1]) {\n",
            "  %param = f32[2048,8192]{1,0} parameter(3), sharding={devices=[4,1,2]0,1,2,3,4,5,6,7 last_tile_dim_replicate}\n",
            "  %param.1 = f32[1]{0} parameter(1), sharding={replicated}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/sharding_constraint[sharding=GSPMDSharding({replicated}) resource_env=ResourceEnv(Mesh(device_ids=array([[0, 1],\\n       [2, 3],\\n       [4, 5],\\n       [6, 7]]), axis_names=(\\'data\\', \\'model\\')), ()) unconstrained_dims=set()]\" source_file=\"/usr/local/lib/python3.9/dist-packages/flax/core/meta.py\" source_line=243}\n",
            "  %call.1 = f32[2048,8192]{1,0} call(f32[2048,8192]{1,0} %param, f32[1]{0} %param.1), to_apply=%parallel_fusion.4\n",
            "  %param.2 = f32[8192,4096]{1,0} parameter(2), sharding={devices=[1,2,4]0,2,4,6,1,3,5,7 last_tile_dim_replicate}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/sharding_constraint[sharding=GSPMDSharding({devices=[1,2,4]0,2,4,6,1,3,5,7 last_tile_dim_replicate}) resource_env=ResourceEnv(Mesh(device_ids=array([[0, 1],\\n       [2, 3],\\n       [4, 5],\\n       [6, 7]]), axis_names=(\\'data\\', \\'model\\')), ()) unconstrained_dims=set()]\" source_file=\"/usr/local/lib/python3.9/dist-packages/flax/core/meta.py\" source_line=243}\n",
            "  %dot = f32[2048,4096]{1,0} dot(f32[2048,8192]{1,0} %call.1, f32[8192,4096]{1,0} %param.2), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=20}\n",
            "  %param.3 = f32[16]{0} parameter(0), sharding={replicated}, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/sharding_constraint[sharding=GSPMDSharding({replicated}) resource_env=ResourceEnv(Mesh(device_ids=array([[0, 1],\\n       [2, 3],\\n       [4, 5],\\n       [6, 7]]), axis_names=(\\'data\\', \\'model\\')), ()) unconstrained_dims=set()]\" source_file=\"/usr/local/lib/python3.9/dist-packages/flax/core/meta.py\" source_line=243}\n",
            "  %copy.12 = f32[16]{0} copy(f32[16]{0} %param.3)\n",
            "  %constant.12 = f32[] constant(-inf)\n",
            "  %reduce-window = f32[64,256]{1,0} reduce-window(f32[2048,8192]{1,0} %param, f32[] %constant.12), window={size=32x32 stride=32x32}, to_apply=%region_0.16\n",
            "  %reduce-window.1 = f32[2,8]{1,0} reduce-window(f32[64,256]{1,0} %reduce-window, f32[] %constant.12), window={size=32x32 stride=32x32}, to_apply=%region_0.16\n",
            "  %reduce = f32[] reduce(f32[2,8]{1,0} %reduce-window.1, f32[] %constant.12), dimensions={0,1}, to_apply=%region_0.16, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0, 1)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=21}\n",
            "  %all-reduce = f32[] all-reduce(f32[] %reduce), channel_id=1, replica_groups={{0,2,4,6},{1,3,5,7}}, use_global_device_ids=true, to_apply=%region_0.16, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/reduce_max[axes=(0, 1)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=21}\n",
            "  %fusion.3 = f32[16]{0} fusion(f32[16]{0} %copy.12, f32[] %all-reduce), kind=kLoop, calls=%fused_computation.3, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/scatter[update_consts=() dimension_numbers=ScatterDimensionNumbers(update_window_dims=(), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,)) indices_are_sorted=True unique_indices=True mode=GatherScatterMode.FILL_OR_DROP]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=24}\n",
            "  %fusion.1 = f32[16]{0} fusion(f32[16]{0} %fusion.3), kind=kLoop, calls=%fused_computation.1, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/dynamic_slice[slice_sizes=(16,)]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "  %fusion.2 = f32[32]{0} fusion(f32[16]{0} %param.3, f32[] %all-reduce), kind=kLoop, calls=%fused_computation.2, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/jit(_roll)/concatenate[dimension=0]\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=25}\n",
            "  %fusion = f32[1]{0} fusion(f32[1]{0} %param.1, f32[32]{0} %fusion.2), kind=kLoop, calls=%fused_computation, metadata={op_name=\"pjit(infer_step)/jit(main)/SuperDot/div\" source_file=\"<ipython-input-3-11318a3f567b>\" source_line=26}\n",
            "  ROOT %tuple = (f32[2048,4096]{1,0}, f32[16]{0}, f32[1]{0}) tuple(f32[2048,4096]{1,0} %dot, f32[16]{0} %fusion.1, f32[1]{0} %fusion)\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note\n",
        "\n",
        "\n",
        "*   In `main.spmd`: The `reduce-window`, `reduce`, and `all-reduce` are for the amax computation.\n",
        "*   The `amax` update uses two fusion functions: (1) `fusion.3` updates the first element. (2) `fusion.1` roll the amax history by concatenation and slicing.\n",
        "*   The `scale` computation uses two fusion functions: (1) `fusion.2` updates the first element and the concatenation. (2) `fusion` does the slicing and then the reduction and division.\n",
        "\n"
      ],
      "metadata": {
        "id": "xLvzDU8S4-1c"
      }
    }
  ]
}